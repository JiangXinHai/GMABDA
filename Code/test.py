# ã€æœ€é¡¶éƒ¨æ·»åŠ ã€‘å…ˆéªŒè¯è„šæœ¬æ˜¯å¦èƒ½æ­£å¸¸æ‰§è¡Œ
print("="*50)
print("è„šæœ¬å¼€å§‹å¯åŠ¨ï¼Œè¿›å…¥åŸºç¡€ç¯å¢ƒæ£€æŸ¥...")
print("="*50)

# å¯¼å…¥æ¨¡å—æ—¶æ·»åŠ æ‰“å°ï¼Œå®šä½æ˜¯å¦æ˜¯å¯¼å…¥å¤±è´¥
try:
    import torch
    print("âœ… torch å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ torch å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
    exit()

try:
    import os
    from PIL import Image
    from torchvision import transforms
    import numpy as np
    print("âœ… åŸºç¡€å›¾åƒå¤„ç†åº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ åŸºç¡€å›¾åƒå¤„ç†åº“å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
    exit()

try:
    from Code.common.Utils import logger
    print("âœ… è‡ªå®šä¹‰ logger å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ è‡ªå®šä¹‰ logger å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
    print("æç¤ºï¼šå¯èƒ½æ˜¯ Code.common.Utils è·¯å¾„é”™è¯¯ï¼Œæˆ– Utils.py ä¸­å­˜åœ¨è¯­æ³•é”™è¯¯")
    exit()

try:
    from Code.common.Config.Configs import diffusionModel_config
    print("âœ… diffusionModel_config å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ diffusionModel_config å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
    exit()

try:
    from Code.diffusion_fine_tune.generator import LoRADiffusionGenerator
    print("âœ… LoRADiffusionGenerator å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ LoRADiffusionGenerator å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
    print("æç¤ºï¼šæ£€æŸ¥ generator.py è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ–‡ä»¶å†…æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯/ä¾èµ–ç¼ºå¤±")
    exit()

try:
    from diffusers import DDPMScheduler
    print("âœ… DDPMScheduler å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ DDPMScheduler å¯¼å…¥å¤±è´¥ï¼š{str(e)}")
    exit()

print("="*50)
print("æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼Œå¼€å§‹æ‰§è¡Œæµ‹è¯•é€»è¾‘...")
print("="*50)

def tensor_to_pil_safe(tensor, target_size):
    """
    å®‰å…¨åœ°å°†å¼ é‡è½¬ä¸ºPILå›¾åƒï¼ˆå½»åº•è§„é¿ç»´åº¦é—®é¢˜ï¼‰
    1. å¼ºåˆ¶è½¬CPUå¹¶å±•å¹³å¤šä½™ç»´åº¦
    2. å›ºå®šç¼©æ”¾ä¸ºç›®æ ‡å°ºå¯¸
    3. ç¡®ä¿é€šé“æ•°ä¸º3
    """
    # 1. è½¬CPU + å»é™¤æ‰¹é‡ç»´åº¦ï¼ˆåªä¿ç•™å•å›¾ï¼‰
    tensor = tensor.detach().cpu()
    if tensor.dim() > 3:
        tensor = tensor[0]  # å–ç¬¬ä¸€å¼ å›¾
    
    # 2. å¤„ç†é€šé“ç»´åº¦ï¼ˆä¸ç®¡åŸå§‹é¡ºåºï¼Œå…ˆç¡®ä¿é€šé“æ•°æ­£ç¡®ï¼‰
    if tensor.size(0) in [1, 3]:
        # è‹¥é€šé“åœ¨ç¬¬ä¸€ç»´ï¼ˆ[3,H,W]æˆ–[1,H,W]ï¼‰ï¼Œè½¬æˆ[H,W,C]
        tensor = tensor.permute(1, 2, 0)
    # æ­¤æ—¶å¼ é‡åº”ä¸º [H,W,C]ï¼Œè‹¥é€šé“æ•°ä¸º1åˆ™æ‰©ä¸º3
    if tensor.size(2) == 1:
        tensor = tensor.repeat(1, 1, 3)
    # ç¡®ä¿é€šé“æ•°æœ€ç»ˆä¸º3ï¼ˆé˜²æ­¢å¼‚å¸¸æƒ…å†µï¼‰
    if tensor.size(2) != 3:
        tensor = tensor[:, :, :3]  # æˆªå–å‰3ä¸ªé€šé“
    
    # 3. è½¬æ¢åˆ°[0,255]èŒƒå›´ï¼ˆé€‚é…PILï¼‰
    tensor = tensor.clamp(-1, 1) if tensor.max() > 1 else tensor.clamp(0, 1)
    if tensor.max() <= 1:
        tensor = (tensor * 255).byte()
    
    # 4. è½¬numpyå†è½¬PILï¼Œæœ€åå¼ºåˆ¶ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸
    img_np = tensor.numpy()
    pil_img = Image.fromarray(img_np)
    return pil_img.resize(target_size, Image.Resampling.LANCZOS)

def save_comparison_grid_pil(images_pil, titles, save_path, nrow=2, padding=10):
    """
    ç”¨PILç›´æ¥æ‹¼æ¥å¯¹æ¯”å›¾ï¼ˆå®Œå…¨ä¸ä¾èµ–å¼ é‡å †å ï¼Œå½»åº•è§£å†³ç»´åº¦é—®é¢˜ï¼‰
    - images_pil: å·²ç»Ÿä¸€å°ºå¯¸çš„PILå›¾åƒåˆ—è¡¨
    - padding: å›¾åƒé—´çš„ç©ºç™½é—´è·ï¼ˆåƒç´ ï¼‰
    """
    # 1. ç¡®è®¤æ‰€æœ‰å›¾åƒå°ºå¯¸ä¸€è‡´
    img_width, img_height = images_pil[0].size
    for img in images_pil:
        assert img.size == (img_width, img_height), f"å›¾åƒå°ºå¯¸ä¸ä¸€è‡´ï¼æœŸæœ›({img_width},{img_height})ï¼Œå®é™…{img.size}"
    
    # 2. è®¡ç®—ç½‘æ ¼æ€»å°ºå¯¸ï¼ˆnrowåˆ—ï¼Œè‡ªåŠ¨åˆ†è¡Œï¼‰
    n_total = len(images_pil)
    n_col = nrow
    n_row = (n_total + n_col - 1) // n_col  # å‘ä¸Šå–æ•´
    total_width = n_col * img_width + (n_col - 1) * padding
    total_height = n_row * img_height + (n_row - 1) * padding
    
    # 3. åˆ›å»ºç©ºç™½ç”»å¸ƒï¼ˆç™½è‰²èƒŒæ™¯ï¼‰
    grid_img = Image.new("RGB", (total_width, total_height), color="white")
    
    # 4. é€ä¸ªç²˜è´´å›¾åƒåˆ°ç”»å¸ƒ
    for idx, img in enumerate(images_pil):
        row = idx // n_col
        col = idx % n_col
        # è®¡ç®—å½“å‰å›¾åƒçš„å·¦ä¸Šè§’åæ ‡
        x = col * (img_width + padding)
        y = row * (img_height + padding)
        grid_img.paste(img, (x, y))
    
    # 5. ä¿å­˜æœ€ç»ˆç½‘æ ¼å›¾
    grid_img.save(save_path)
    logger.info(f"ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜ï¼š{save_path}ï¼ˆç½‘æ ¼å°ºå¯¸ï¼š{total_width}x{total_height}ï¼‰")

def calculate_metrics_safe(original_tensor, predicted_tensor, device):
    """å®‰å…¨è®¡ç®—MSEå’ŒPSNRï¼ˆå±•å¹³æ‰€æœ‰ç»´åº¦ï¼Œåªçœ‹æ•°å€¼å·®å¼‚ï¼‰"""
    # 1. ç»Ÿä¸€è®¾å¤‡ + è½¬CPUï¼ˆé¿å…GPUè®¡ç®—è¯¯å·®ï¼‰
    original = original_tensor.detach().to(device)
    predicted = predicted_tensor.detach().to(device)
    
    # 2. å±•å¹³ä¸º1ç»´å¼ é‡ï¼ˆå½»åº•å¿½ç•¥ç©ºé—´ç»´åº¦é¡ºåºï¼‰
    original_flat = original.flatten()
    predicted_flat = predicted.flatten()
    
    # 3. ç¡®ä¿ä¸¤ä¸ªå¼ é‡é•¿åº¦ä¸€è‡´ï¼ˆå–è¾ƒçŸ­çš„é•¿åº¦æˆªæ–­ï¼‰
    min_len = min(len(original_flat), len(predicted_flat))
    original_flat = original_flat[:min_len]
    predicted_flat = predicted_flat[:min_len]
    
    # 4. è½¬æ¢åˆ°[0,1]èŒƒå›´
    original_flat = original_flat.clamp(-1, 1)
    predicted_flat = predicted_flat.clamp(-1, 1)
    original_flat = (original_flat + 1) / 2
    predicted_flat = (predicted_flat + 1) / 2
    
    # 5. è®¡ç®—æŒ‡æ ‡
    mse = torch.mean((original_flat - predicted_flat) ** 2)
    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse)) if mse > 0 else 100.0
    return mse.item(), psnr.item()

def test_lora_generator_with_ddpm():
    """
    æµ‹è¯• LoRA ç”Ÿæˆå™¨ + DDPMScheduler å®Œæ•´æµç¨‹ï¼ˆå«å®Œæ•´å»å™ªï¼‰
    æ ¸å¿ƒæ”¹è¿›ï¼šä»éšæœºæ—¶é—´æ­¥è¿ç»­å»å™ªåˆ°0æ­¥ï¼Œç¡®ä¿é¢„æµ‹å›¾æ¥è¿‘åŸå›¾
    """
    # -------------------------- 1. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶ --------------------------
    # 1.1 åˆå§‹åŒ– LoRA ç”Ÿæˆå™¨ + å›ºå®šå‚æ•°
    try:
        generator = LoRADiffusionGenerator()
        # ç›´æ¥ä½¿ç”¨åŸå§‹ UNetï¼ˆè·³è¿‡ LoRAï¼‰
        generator.unet = generator.pipeline.unet.to(generator.device)
        logger.info(f"ğŸ” UNet æƒé‡éªŒè¯ï¼š")
        logger.info(f"UNet è®¾å¤‡: {generator.pipeline.unet.device}")
        logger.info(f"UNet ç¬¬ä¸€å±‚æƒé‡èŒƒå›´: {generator.pipeline.unet.conv_in.weight.min().item():.4f} ~ {generator.pipeline.unet.conv_in.weight.max().item():.4f}")
        # æ­£å¸¸æƒ…å†µï¼šæƒé‡èŒƒå›´åº”è¯¥åœ¨ [-0.1, 0.1] é™„è¿‘ï¼Œä¸æ˜¯å…¨ 0 æˆ–å¼‚å¸¸å€¼
        model_device = generator.device
        target_size = (diffusionModel_config.IMAGE_SIZE, diffusionModel_config.IMAGE_SIZE)
        logger.info(f"âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸï¼šè®¾å¤‡={model_device}ï¼Œç›®æ ‡å°ºå¯¸={target_size}")
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        return

    # 1.2 åˆå§‹åŒ– DDPMScheduler
    try:
        num_train_timesteps = getattr(diffusionModel_config, "NUM_TRAIN_TIMESTEPS", 1000)
        beta_start = getattr(diffusionModel_config, "BETA_START", 0.0001)
        beta_end = getattr(diffusionModel_config, "BETA_END", 0.02)

        scheduler = DDPMScheduler(
            num_train_timesteps=num_train_timesteps,
            beta_start=beta_start,
            beta_end=beta_end,
            beta_schedule="linear",
            clip_sample=True,
            prediction_type="epsilon",
        )
        scheduler.set_timesteps(num_inference_steps=num_train_timesteps, device=model_device)  # é€‚é…å®Œæ•´å»å™ªæ­¥é•¿
        logger.info("âœ… DDPMScheduler åˆå§‹åŒ–æˆåŠŸï¼ˆé€‚é…å®Œæ•´å»å™ªæµç¨‹ï¼‰")
    except Exception as e:
        logger.error(f"âŒ DDPMScheduler åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        return

    # -------------------------- 2. å‡†å¤‡æµ‹è¯•æ•°æ® --------------------------
    test_image_path = "/home/jiangxinhai/GMABDA/Code/diffusion_fine_tune/test.jpg"
    output_dir = "/home/jiangxinhai/GMABDA/Code/diffusion_fine_tune/test_results"
    os.makedirs(output_dir, exist_ok=True)

    # 2.1 åŠ è½½å¹¶ç¼©æ”¾åŸå§‹å›¾ç‰‡
    try:
        raw_pil = Image.open(test_image_path).convert("RGB")
        resized_original_pil = raw_pil.resize(target_size, Image.Resampling.LANCZOS)
        resized_original_pil.save(f"{output_dir}/01_original_resized.jpg")
        logger.info(f"âœ… åŸå§‹å›¾åŠ è½½å®Œæˆï¼Œç¼©æ”¾åå°ºå¯¸ï¼š{resized_original_pil.size}")
    except Exception as e:
        logger.error(f"âŒ åŸå§‹å›¾åŠ è½½å¤±è´¥ï¼š{str(e)}")
        return

    # 2.2 å›¾åƒè½¬æ¨¡å‹è¾“å…¥å¼ é‡
    try:
        transform = transforms.Compose([
            transforms.Resize(target_size),
            transforms.ToTensor(),  # [3,H,W]ï¼ŒèŒƒå›´[0,1]
            lambda x: x.unsqueeze(0)  # [1,3,H,W]
        ])
        input_tensor = transform(raw_pil).to(model_device)
        logger.info(f"âœ… æ¨¡å‹è¾“å…¥å¼ é‡å‡†å¤‡å®Œæˆï¼šå½¢çŠ¶={input_tensor.shape}ï¼Œè®¾å¤‡={input_tensor.device}")
    except Exception as e:
        logger.error(f"âŒ è¾“å…¥å¼ é‡è½¬æ¢å¤±è´¥ï¼š{str(e)}")
        return

    # 2.3 ç”Ÿæˆæ–‡æœ¬åµŒå…¥ï¼ˆä¼˜åŒ–ï¼šæ›´è´´è¿‘å›¾åƒå†…å®¹çš„æç¤ºè¯ï¼‰
    try:
        # å»ºè®®æ ¹æ®æµ‹è¯•å›¾å†…å®¹ä¿®æ”¹ï¼ˆå¦‚æµ‹è¯•å›¾æ˜¯çŒ«ï¼Œå°±å†™"a photo of a cat, realistic"ï¼‰
        test_prompt = "a photo of a cat, realistic"
        text_embeds = generator.get_text_embeddings([test_prompt]).to(model_device)
        logger.info(f"âœ… æ–‡æœ¬åµŒå…¥ç”Ÿæˆå®Œæˆï¼šå½¢çŠ¶={text_embeds.shape}")
    except Exception as e:
        logger.error(f"âŒ æ–‡æœ¬åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        return

    # -------------------------- 3. æ ¸å¿ƒæµç¨‹ï¼šåŠ å™ª + å®Œæ•´å»å™ª --------------------------


    # åŸå›¾ â†’ latent
    latent = generator.image_to_latent(input_tensor)

    # åŠ å™ª
    timestep = torch.randint(400, 401, (latent.size(0),), device=model_device, dtype=torch.int64)
    noise = torch.randn_like(latent)
    noisy_latent = scheduler.add_noise(latent, noise, timestep)

    # latent â†’ å›¾åƒ
    noisy_image = generator.latent_to_image(noisy_latent)
    noisy_pil = transforms.ToPILImage()(noisy_image[0].cpu())
    noisy_pil.save(f"{output_dir}/test_noisy.jpg")



    # åœ¨â€œå›¾åƒè½¬æ½œç©ºé—´â€å‰ï¼Œæ·»åŠ  VAE æµ‹è¯•
    try:
        # åŸå›¾ â†’ æ½œç©ºé—´ â†’ é‡æ„å›¾åƒ
        latent = generator.image_to_latent(input_tensor)
        recon_image_tensor = generator.latent_to_image(latent)
        recon_pil = transforms.ToPILImage()(recon_image_tensor[0].cpu())
        recon_pil.save(f"{output_dir}/00_vae_recon.jpg")
        logger.info("âœ… VAE é‡æ„å›¾åƒä¿å­˜ï¼š00_vae_recon.jpgï¼ˆéªŒè¯ VAE è½¬æ¢ï¼‰")
        
        # å¯¹æ¯”åŸå›¾å’Œé‡æ„å›¾
        if np.array_equal(np.array(recon_pil), np.array(resized_original_pil)):
            logger.info("VAE è½¬æ¢æ­£å¸¸ï¼šé‡æ„å›¾ä¸åŸå›¾ä¸€è‡´")
        else:
            logger.error("VAE è½¬æ¢å¼‚å¸¸ï¼šé‡æ„å›¾ä¸åŸå›¾å·®å¼‚å¤§ï¼Œéœ€æ£€æŸ¥ VAE é€»è¾‘ï¼")
    except Exception as e:
        logger.error(f"âŒ VAE æµ‹è¯•å¤±è´¥ï¼š{str(e)}")
    # 3.1 å›¾åƒè½¬æ½œç©ºé—´
    try:
        latent = generator.image_to_latent(input_tensor)
        logger.info(f"âœ… å›¾åƒè½¬æ½œç©ºé—´å®Œæˆï¼šå½¢çŠ¶={latent.shape}")
    except Exception as e:
        logger.error(f"âŒ å›¾åƒè½¬æ½œç©ºé—´å¤±è´¥ï¼š{str(e)}")
        return

    # 3.2 éšæœºåŠ å™ªï¼ˆä¼˜åŒ–ï¼šåªé€‰ä½å™ªå£°é˜¶æ®µï¼Œå»å™ªæ•ˆæœæ›´ç›´è§‚ï¼‰
    try:
        # éšæœºæ—¶é—´æ­¥èŒƒå›´ï¼š50~200ï¼ˆä½å™ªå£°é˜¶æ®µï¼Œé¿å…å»å™ªæ­¥æ•°è¿‡å¤šï¼‰
        timestep = torch.randint(400, 401, (latent.size(0),), device=model_device, dtype=torch.int64)
        current_timestep_val = timestep.item()
        
        noise = torch.randn_like(latent)
        noisy_latent = scheduler.add_noise(latent, noise, timestep)

        # ä¿å­˜åŠ å™ªå›¾
        noisy_image_tensor = generator.latent_to_image(noisy_latent)
        noisy_pil = tensor_to_pil_safe(noisy_image_tensor, target_size)
        noisy_pil.save(f"{output_dir}/02_noisy_image_t{current_timestep_val}.jpg")
        logger.info(f"âœ… æ½œç©ºé—´åŠ å™ªå®Œæˆï¼šæ—¶é—´æ­¥={current_timestep_val}ï¼ˆä½å™ªå£°é˜¶æ®µï¼‰ï¼Œå™ªç‚¹å›¾å·²ä¿å­˜")
    except Exception as e:
        logger.error(f"âŒ æ½œç©ºé—´åŠ å™ªå¤±è´¥ï¼š{str(e)}")
        return

    # 3.3 å®Œæ•´å»å™ªæµç¨‹ï¼ˆæ ¸å¿ƒæ”¹è¿›ï¼šä»å½“å‰æ—¶é—´æ­¥è¿ç»­é™åˆ°0æ­¥ï¼‰
    try:
        with torch.no_grad():
            # 1. ç”Ÿæˆä»å½“å‰æ—¶é—´æ­¥åˆ°0æ­¥çš„å®Œæ•´åºåˆ—ï¼ˆå€’åºï¼šcurrent_timestep_val â†’ 0ï¼‰
            full_timesteps = torch.arange(current_timestep_val, -1, -1, device=model_device, dtype=torch.int64)
            total_steps = len(full_timesteps)
            logger.info(f"ğŸ”„ å¼€å§‹å®Œæ•´å»å™ªï¼šä»æ—¶é—´æ­¥ {current_timestep_val} åˆ° 0ï¼Œå…± {total_steps} æ­¥")

            # 2. åˆå§‹åŒ–å»å™ª latentï¼ˆä»åŠ å™ªåçš„ latent å¼€å§‹ï¼‰
            denoising_latent = noisy_latent.clone()

            # 3. é€æ­¥å»å™ªï¼ˆå¾ªç¯æ‰§è¡Œæ‰€æœ‰æ—¶é—´æ­¥ï¼‰
            for step_idx, t in enumerate(full_timesteps):
                # æ—¶é—´æ­¥ä¿æŒæ‰¹é‡ç»´åº¦ï¼ˆåŒ¹é…æ¨¡å‹è¾“å…¥è¦æ±‚ï¼‰
                t_tensor = t.unsqueeze(0)
                # è®°å½•å»å™ªå‰ latent
                prev_latent = denoising_latent.clone()
                # æ¨¡å‹é¢„æµ‹å½“å‰æ­¥çš„å™ªå£°
                unet_output = generator.predict_noise(
                    noisy_latents=denoising_latent,
                    timesteps=t_tensor,
                    text_embeds=text_embeds
                )
                pred_noise = unet_output.sample

                # è°ƒåº¦å™¨æ›´æ–° latentï¼ˆå»å™ªä¸€æ­¥ï¼‰
                denoise_out = scheduler.step(
                    model_output=pred_noise,
                    timestep=t_tensor,
                    sample=denoising_latent,
                    return_dict=True
                )
                denoising_latent = denoise_out.prev_sample
                # æ‰“å°å˜åŒ–é‡
                delta = torch.norm(denoising_latent - prev_latent).item()
                logger.info(f"æ—¶é—´æ­¥ {t}: å˜åŒ–é‡ = {delta:.6f}")
                logger.info(f"å½“å‰æ—¶é—´æ­¥: {t}, ä¸‹ä¸€æ—¶é—´æ­¥: {scheduler.previous_timestep(t)}")

                # æ¯50æ­¥æ‰“å°è¿›åº¦ï¼ˆé¿å…æ—¥å¿—å†—ä½™ï¼‰
                if (step_idx + 1) % 50 == 0 or step_idx == total_steps - 1:
                    logger.info(f"ğŸ”„ å»å™ªè¿›åº¦ï¼š{step_idx + 1}/{total_steps} æ­¥ï¼ˆå½“å‰æ—¶é—´æ­¥ï¼š{t}ï¼‰")
                    denoising_img = generator.latent_to_image(denoising_latent)
                    denoising_pil = tensor_to_pil_safe(denoising_img, target_size)
                    denoising_pil.save(f"{output_dir}/03_denoise_step_t{t}.jpg")

            # 4. å»å™ªå®Œæˆï¼šæœ€ç»ˆ latent å¯¹åº”0æ—¶é—´æ­¥ï¼ˆæ— å™ªå£°ï¼‰
            final_denoised_latent = denoising_latent
            pred_original_latent = final_denoised_latent  # æ­¤ latent åº”æ¥è¿‘åŸå›¾æ½œç©ºé—´
        logger.info("âœ… å®Œæ•´å»å™ªæµç¨‹ç»“æŸï¼")
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´å»å™ªæµç¨‹å¤±è´¥ï¼š{str(e)}")
        return

    # -------------------------- 4. ç»“æœä¿å­˜ä¸éªŒè¯ --------------------------
    # 4.2 ä¿å­˜æœ€ç»ˆé¢„æµ‹å›¾
    pred_original_image = generator.latent_to_image(pred_original_latent)
    pred_original_pil = tensor_to_pil_safe(pred_original_image, target_size)
    pred_original_pil.save(f"{output_dir}/04_final_predicted_original.jpg")

    # 4.3 è®¡ç®—å¹¶ä¿å­˜æŒ‡æ ‡ï¼ˆæ­¤æ—¶MSEåº”å¤§å¹…é™ä½ï¼‰
    mse, psnr = calculate_metrics_safe(input_tensor, pred_original_latent, model_device)
    logger.info(f"\nğŸ“Š æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡ï¼š")
    logger.info(f"   MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰ï¼š{mse:.6f}ï¼ˆè¶Šå°è¶Šæ¥è¿‘åŸå›¾ï¼‰")
    logger.info(f"   PSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰ï¼š{psnr:.2f} dBï¼ˆè¶Šå¤§è¶Šæ¸…æ™°ï¼‰")
    with open(f"{output_dir}/metrics.txt", "w") as f:
        f.write(f"æµ‹è¯•æ—¶é—´æ­¥èŒƒå›´ï¼š{current_timestep_val} â†’ 0\n")
        f.write(f"æ€»å»å™ªæ­¥æ•°ï¼š{total_steps}\n")
        f.write(f"MSE: {mse:.6f}\n")
        f.write(f"PSNR: {psnr:.2f} dB\n")

    # 4.4 æ‹¼æ¥å¯¹æ¯”å›¾ï¼ˆåŸå›¾ + åŠ å™ªå›¾ + æœ€ç»ˆé¢„æµ‹å›¾ï¼‰
    comparison_images = [
        resized_original_pil,
        noisy_pil,
        pred_original_pil
    ]
    save_comparison_grid_pil(
        images_pil=comparison_images,
        titles=["Original", f"Noisy (t={current_timestep_val})", "Final Predicted"],
        save_path=f"{output_dir}/05_comparison_grid.jpg",
        nrow=3,  # 3å¼ å›¾æ¨ªå‘æ’åˆ—ï¼Œå¯¹æ¯”æ›´ç›´è§‚
        padding=10
    )

    # -------------------------- 5. æµ‹è¯•æ€»ç»“ --------------------------
    logger.info(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•æµç¨‹å®Œæˆï¼")
    logger.info(f"ç»“æœæ–‡ä»¶è·¯å¾„ï¼š{output_dir}")
    logger.info("å…³é”®æ–‡ä»¶è¯´æ˜ï¼š")
    logger.info("1. 01_original_resized.jpgï¼šç¼©æ”¾åçš„åŸå§‹å›¾")
    logger.info("2. 02_noisy_image_tXXX.jpgï¼šåŠ å™ªå›¾ï¼ˆæµ‹è¯•èµ·ç‚¹ï¼‰")
    logger.info("3. 03_denoise_step_tXXX.jpgï¼šå»å™ªä¸­é—´æ­¥éª¤å›¾ï¼ˆå¯é€‰ï¼‰")
    logger.info("4. 04_final_predicted_original.jpgï¼šæœ€ç»ˆé¢„æµ‹å›¾ï¼ˆåº”æ¥è¿‘åŸå›¾ï¼‰")
    logger.info("5. 05_comparison_grid.jpgï¼šä¸‰å›¾å¯¹æ¯”ï¼ˆç›´è§‚æŸ¥çœ‹å»å™ªæ•ˆæœï¼‰")
    logger.info("6. metrics.txtï¼šé‡åŒ–æŒ‡æ ‡ï¼ˆMSE<0.05ã€PSNR>15dBä¸ºè¾ƒå¥½æ•ˆæœï¼‰")


if __name__ == "__main__":
    # å¯åŠ¨æµ‹è¯•
    logger.info("="*60)
    logger.info("å¼€å§‹æ‰§è¡Œ LoRA ç”Ÿæˆå™¨ + DDPMScheduler å®Œæ•´æµ‹è¯•ï¼ˆå«å®Œæ•´å»å™ªï¼‰")
    logger.info("="*60)
    test_lora_generator_with_ddpm()