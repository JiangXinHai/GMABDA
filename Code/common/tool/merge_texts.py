import json
import os

def merge_json_files_no_duplicate(source_file1: str, source_file2: str, target_file: str) -> None:
    """
    åˆå¹¶ä¸¤ä¸ªJSONæ–‡ä»¶ï¼ˆæ ¼å¼ä¸ºJSONå¯¹è±¡åˆ—è¡¨ï¼Œæ— éœ€å»é‡ï¼Œç›´æ¥æ‹¼æ¥ï¼‰
    
    å‚æ•°:
        source_file1: ç¬¬ä¸€ä¸ªæºJSONæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ "data1.json"ï¼‰
        source_file2: ç¬¬äºŒä¸ªæºJSONæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ "data2.json"ï¼‰
        target_file: åˆå¹¶åçš„ç›®æ ‡JSONæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ "merged_data.json"ï¼‰
    """
    # è¯»å–å•ä¸ªJSONæ–‡ä»¶å¹¶æ ¡éªŒæ ¼å¼
    def load_json_file(file_path: str) -> list:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨")
        
        # è§£æJSONå¹¶æ ¡éªŒç»“æ„
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                # ç¡®ä¿JSONé¡¶å±‚æ˜¯åˆ—è¡¨ï¼ˆç¬¦åˆ [{}, {}, ...] æ ¼å¼ï¼‰
                if not isinstance(data, list):
                    raise ValueError(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸æ˜¯JSONåˆ—è¡¨æ ¼å¼ï¼ˆéœ€ç”¨ [] åŒ…è£¹æ‰€æœ‰å¯¹è±¡ï¼‰")
                
                # æ ¡éªŒæ¯ä¸ªå¯¹è±¡æ˜¯å¦åŒ…å«å¿…éœ€é”®ï¼ˆåŒ¹é…ä½ æä¾›çš„JSONç»“æ„ï¼‰
                required_keys = {"words", "image_id", "aspects", "opinions", "noun"}
                for idx, item in enumerate(data):
                    if not isinstance(item, dict):
                        raise ValueError(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ç¬¬ {idx+1} ä¸ªå…ƒç´ ä¸æ˜¯JSONå¯¹è±¡")
                    missing_keys = required_keys - item.keys()
                    if missing_keys:
                        raise ValueError(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ç¬¬ {idx+1} ä¸ªå¯¹è±¡ç¼ºå¤±é”®ï¼š{missing_keys}")
                
                return data
        
        except json.JSONDecodeError as e:
            raise ValueError(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' JSONæ ¼å¼æ— æ•ˆï¼ˆå¦‚æ‹¬å·ä¸åŒ¹é…ã€é€—å·é”™è¯¯ï¼‰ï¼Œè¯¦æƒ…ï¼š{str(e)}")
        except Exception as e:
            raise RuntimeError(f"è¯»å–æ–‡ä»¶ '{file_path}' å¤±è´¥ï¼Œè¯¦æƒ…ï¼š{str(e)}")
    
    # æ‰§è¡Œåˆå¹¶é€»è¾‘
    try:
        # è¯»å–ä¸¤ä¸ªæºæ–‡ä»¶æ•°æ®
        data1 = load_json_file(source_file1)
        data2 = load_json_file(source_file2)
        
        # ç›´æ¥æ‹¼æ¥åˆ—è¡¨ï¼ˆæ— éœ€å»é‡ï¼‰
        merged_data = data1 + data2
        
        # å†™å…¥ç›®æ ‡æ–‡ä»¶ï¼ˆä¿ç•™ç¼©è¿›ï¼Œæ”¯æŒéASCIIå­—ç¬¦ï¼‰
        with open(target_file, "w", encoding="utf-8") as f:
            json.dump(merged_data, f, indent=4, ensure_ascii=False)
        
        # è¾“å‡ºåˆå¹¶ç»“æœ
        print(f"âœ… åˆå¹¶å®Œæˆï¼")
        print(f"ğŸ“ æºæ–‡ä»¶1ï¼š{source_file1}ï¼ˆ{len(data1)} ä¸ªå¯¹è±¡ï¼‰")
        print(f"ğŸ“ æºæ–‡ä»¶2ï¼š{source_file2}ï¼ˆ{len(data2)} ä¸ªå¯¹è±¡ï¼‰")
        print(f"ğŸ¯ ç›®æ ‡æ–‡ä»¶ï¼š{target_file}ï¼ˆå…± {len(merged_data)} ä¸ªå¯¹è±¡ï¼‰")
    
    except Exception as e:
        print(f"âŒ åˆå¹¶å¤±è´¥ï¼š{str(e)}")


# ------------------- ä½¿ç”¨ç¤ºä¾‹ -------------------
if __name__ == "__main__":
    # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„/ç»å¯¹è·¯å¾„å‡å¯ï¼‰
    SOURCE_FILE_train = "/home/jiangxinhai/GMABDA/Code/test/AoM/AoM-main/src/data/twitter2015/train.json"  # ç¬¬ä¸€ä¸ªæºJSONæ–‡ä»¶
    SOURCE_FILE_train_2 = "/home/jiangxinhai/GMABDA/Data/twitter2015/generator_texts/train_texts/train_generated.json"  # ç¬¬äºŒä¸ªæºJSONæ–‡ä»¶
    TARGET_FILE_train_final = "/home/jiangxinhai/GMABDA/Code/test/AoM/AoM-main/src/data/twitter2015_augment_v1/train.json"  # åˆå¹¶åçš„ç›®æ ‡æ–‡ä»¶
    
    # è°ƒç”¨åˆå¹¶å‡½æ•°
    merge_json_files_no_duplicate(SOURCE_FILE_train, SOURCE_FILE_train_2, TARGET_FILE_train_final)